{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ac5334a-a9c7-4878-8d48-d98db23e8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed345d68-ea5a-412d-a356-5c9585dde958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2825a0d0-20b9-411b-be37-5a9fa06decb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../home/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5a08a9-02c3-451c-a984-30b654c49799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 13:19:34.118347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-20 13:19:40,368\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "530a9b1c-7bcd-41a0-a03c-980949ddc88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anaconda3\t\t\t       modeling.ipynb\n",
      " Anaconda3-2024.10-1-Linux-x86_64.sh   modeling.py\n",
      " Anaconda3-2025.06-0-Linux-x86_64.sh   Musique\n",
      " Bureau\t\t\t\t       Public\n",
      " collect_hw_vm.sh\t\t       snap\n",
      " datasets\t\t\t       T√©l√©chargements\n",
      " Documents\t\t\t      'testing modularisation.ipynb'\n",
      " Images\t\t\t\t       Untitled.ipynb\n",
      " Mod√®les\t\t\t       Vid√©os\n"
     ]
    }
   ],
   "source": [
    "!ls /home/user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90b3cac-4e01-4a46-bb04-ac5843a8f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /home/user/modeling.ipynb to python\n",
      "[NbConvertApp] Writing 9660 bytes to /home/user/modeling.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python /home/user/modeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2f490b-0623-4f8c-86e7-e0b1c68cc92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emnaaS\n",
      "ac026871943a805c04cfaa7af4cf1a0734c83779\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/home/user/.env\")\n",
    "DagsHub_username = os.getenv(\"DagsHub_username\")\n",
    "DagsHub_token=os.getenv(\"DagsHub_token\")\n",
    "\n",
    "print(os.getenv(\"DagsHub_username\"))\n",
    "print(os.getenv(\"DagsHub_token\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c81fa5-57ac-4ba4-96c8-a3ca369656fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']= DagsHub_username\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = DagsHub_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5929a78-dd03-442b-9e5a-1fcf70c3a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as emnaaS\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as emnaaS\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"emnaaS/kmeans_repo\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"emnaaS/kmeans_repo\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository emnaaS/kmeans_repo initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository emnaaS/kmeans_repo initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='emnaaS', repo_name='kmeans_repo', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc077e95-c13e-4e8b-9fb6-ec04036f42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 images with labels\n"
     ]
    }
   ],
   "source": [
    "from modeling import load_image_dataset\n",
    "images, labels = load_image_dataset(\n",
    "    image_dir=\"/home/user/datasets/splits/batch_1000\",\n",
    "    labels_file=\"/home/user/datasets/trainLabels_cropped.csv\",\n",
    "    max_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00516de-9593-4dd6-a087-f6d32fda82b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape (100, 196608)\n",
      "labels shape (100,)\n"
     ]
    }
   ],
   "source": [
    "from modeling import prepare_data\n",
    "images_flat, labels_flat = prepare_data(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b799434-15a7-4d22-8eac-9071f99e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import K_Means_Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61015141-c7fa-4182-9178-60f21c91137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 13:33:48,264\tINFO worker.py:2013 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node:192.168.62.206': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'object_store_memory': 9293700710.0, 'memory': 21685301658.0}\n",
      "Data splitting & Ray.put: 0.053s\n",
      "\n",
      "=== Training Started ===\n",
      "\n",
      "--- Iteration 1 ---\n",
      "\u001b[36m(Worker pid=290543)\u001b[0m Worker - Distance computation: 0.406s | Aggregation: 0.036s | Total: 0.490s\n",
      "Ray.get (collection): 0.905s\n",
      "Result aggregation: 0.008s\n",
      "Centroid update: 0.006s\n",
      "Convergence check: 0.005s | Center shift: 267.837549\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Ray.get (collection): 0.482s\n",
      "Result aggregation: 0.006s\n",
      "Centroid update: 0.004s\n",
      "Convergence check: 0.003s | Center shift: 72.524473\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Ray.get (collection): 0.471s\n",
      "Result aggregation: 0.004s\n",
      "Centroid update: 0.004s\n",
      "Convergence check: 0.003s | Center shift: 40.830633\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Ray.get (collection): 0.432s\n",
      "Result aggregation: 0.004s\n",
      "Centroid update: 0.004s\n",
      "Convergence check: 0.003s | Center shift: 8.630597\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Ray.get (collection): 0.432s\n",
      "Result aggregation: 0.004s\n",
      "Centroid update: 0.005s\n",
      "Convergence check: 0.003s | Center shift: 4.117359\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Ray.get (collection): 0.477s\n",
      "Result aggregation: 0.004s\n",
      "Centroid update: 0.004s\n",
      "Convergence check: 0.003s | Center shift: 0.000000\n",
      "\n",
      "‚úì Converged after 6 iterations\n",
      "\n",
      "=== Training Summary ===\n",
      "Total training time: 3.499s\n",
      "Number of iterations: 6\n",
      "\n",
      "Collection times per iteration: ['0.905s', '0.482s', '0.471s', '0.432s', '0.432s', '0.477s']\n",
      "Average collection time: 0.533s\n",
      "Somme collection time: 3.200s\n",
      "Average dispatch time: 0.009s\n",
      "Average aggregation time: 0.005s\n",
      "Average centroid update time: 0.005s\n",
      "Average convergence check time: 0.004s\n",
      "Training time = 3.50 seconds\n",
      "\n",
      "‚úì Logged centroids, iterations, and cluster sizes to MLflow successfully.\n",
      "\n",
      "üèÉ View run righteous-shrimp-18 at: https://dagshub.com/emnaaS/kmeans_repo.mlflow/#/experiments/0/runs/8efae1dc4bb1454bbe0b669eefd56c28\n",
      "üß™ View experiment at: https://dagshub.com/emnaaS/kmeans_repo.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import ray\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # MLflow: log parameters\n",
    "    mlflow.log_param(\"n_clusters\", 3)\n",
    "    mlflow.log_param(\"max_iter\", 500)\n",
    "    mlflow.log_param(\"num_workers\", 2)\n",
    "    mlflow.log_param(\"num_images\", len(images_flat))\n",
    "    \n",
    "    # Ray memory configuration\n",
    "    os.environ['RAY_memory_usage_threshold'] = '0.97'\n",
    "    os.environ['RAY_memory_monitor_refresh_ms'] = '250'\n",
    "    num_features = images_flat.shape[1]\n",
    "    mlflow.log_param(\"num_features\", num_features)\n",
    "\n",
    "    # Shutdown previous Ray cluster if needed\n",
    "    if ray.is_initialized():\n",
    "        ray.shutdown()\n",
    "\n",
    "    # Init Ray\n",
    "    ray.init(num_cpus=2)\n",
    "    print(ray.cluster_resources())\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    kmeans_dist = K_Means_Distributed(\n",
    "        n_clusters=3,\n",
    "        max_iter=500,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    kmeans_dist.fit(images_flat)\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time = {training_time:.2f} seconds\")\n",
    "\n",
    "    # MLflow: log training time\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "\n",
    "    # Retrieve results from your KMeans class\n",
    "    centroids = kmeans_dist.cluster_centers_\n",
    "    num_iterations = kmeans_dist.number_of_iter\n",
    "    cluster_labels = kmeans_dist.labels_\n",
    "\n",
    "    # MLflow: Log iteration count\n",
    "    mlflow.log_metric(\"iterations\", num_iterations)\n",
    "\n",
    "    # Compute cluster sizes\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    cluster_size_dict = {int(k): int(v) for k, v in zip(unique, counts)}\n",
    "\n",
    "    # MLflow: Log size of each cluster\n",
    "    for cluster_id, size in cluster_size_dict.items():\n",
    "        mlflow.log_metric(f\"cluster_{cluster_id}_size\", size)\n",
    "\n",
    "    # Save centroids\n",
    "    np.save(\"centroids.npy\", centroids)\n",
    "    mlflow.log_artifact(\"centroids.npy\")\n",
    "\n",
    "    # Save cluster report\n",
    "    with open(\"cluster_sizes.json\", \"w\") as f:\n",
    "        json.dump(cluster_size_dict, f, indent=4)\n",
    "\n",
    "    mlflow.log_artifact(\"cluster_sizes.json\")\n",
    "\n",
    "    print(\"\\n‚úì Logged centroids, iterations, and cluster sizes to MLflow successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6826e3-5971-442f-9c68-01368fd41604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7a223d0-663d-4b9f-a3c4-dd9926533b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlflow\n",
      "Version: 2.22.2\n",
      "Summary: MLflow is an open source platform for the complete machine learning lifecycle\n",
      "Home-page: https://mlflow.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: Copyright 2018 Databricks, Inc.  All rights reserved.\n",
      "\n",
      "                                Apache License\n",
      "                           Version 2.0, January 2004\n",
      "                        http://www.apache.org/licenses/\n",
      "\n",
      "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
      "\n",
      "   1. Definitions.\n",
      "\n",
      "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
      "      and distribution as defined by Sections 1 through 9 of this document.\n",
      "\n",
      "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
      "      the copyright owner that is granting the License.\n",
      "\n",
      "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
      "      other entities that control, are controlled by, or are under common\n",
      "      control with that entity. For the purposes of this definition,\n",
      "      \"control\" means (i) the power, direct or indirect, to cause the\n",
      "      direction or management of such entity, whether by contract or\n",
      "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
      "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
      "\n",
      "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
      "      exercising permissions granted by this License.\n",
      "\n",
      "      \"Source\" form shall mean the preferred form for making modifications,\n",
      "      including but not limited to software source code, documentation\n",
      "      source, and configuration files.\n",
      "\n",
      "      \"Object\" form shall mean any form resulting from mechanical\n",
      "      transformation or translation of a Source form, including but\n",
      "      not limited to compiled object code, generated documentation,\n",
      "      and conversions to other media types.\n",
      "\n",
      "      \"Work\" shall mean the work of authorship, whether in Source or\n",
      "      Object form, made available under the License, as indicated by a\n",
      "      copyright notice that is included in or attached to the work\n",
      "      (an example is provided in the Appendix below).\n",
      "\n",
      "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
      "      form, that is based on (or derived from) the Work and for which the\n",
      "      editorial revisions, annotations, elaborations, or other modifications\n",
      "      represent, as a whole, an original work of authorship. For the purposes\n",
      "      of this License, Derivative Works shall not include works that remain\n",
      "      separable from, or merely link (or bind by name) to the interfaces of,\n",
      "      the Work and Derivative Works thereof.\n",
      "\n",
      "      \"Contribution\" shall mean any work of authorship, including\n",
      "      the original version of the Work and any modifications or additions\n",
      "      to that Work or Derivative Works thereof, that is intentionally\n",
      "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
      "      or by an individual or Legal Entity authorized to submit on behalf of\n",
      "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
      "      means any form of electronic, verbal, or written communication sent\n",
      "      to the Licensor or its representatives, including but not limited to\n",
      "      communication on electronic mailing lists, source code control systems,\n",
      "      and issue tracking systems that are managed by, or on behalf of, the\n",
      "      Licensor for the purpose of discussing and improving the Work, but\n",
      "      excluding communication that is conspicuously marked or otherwise\n",
      "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
      "\n",
      "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
      "      on behalf of whom a Contribution has been received by Licensor and\n",
      "      subsequently incorporated within the Work.\n",
      "\n",
      "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
      "      this License, each Contributor hereby grants to You a perpetual,\n",
      "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
      "      copyright license to reproduce, prepare Derivative Works of,\n",
      "      publicly display, publicly perform, sublicense, and distribute the\n",
      "      Work and such Derivative Works in Source or Object form.\n",
      "\n",
      "   3. Grant of Patent License. Subject to the terms and conditions of\n",
      "      this License, each Contributor hereby grants to You a perpetual,\n",
      "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
      "      (except as stated in this section) patent license to make, have made,\n",
      "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
      "      where such license applies only to those patent claims licensable\n",
      "      by such Contributor that are necessarily infringed by their\n",
      "      Contribution(s) alone or by combination of their Contribution(s)\n",
      "      with the Work to which such Contribution(s) was submitted. If You\n",
      "      institute patent litigation against any entity (including a\n",
      "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
      "      or a Contribution incorporated within the Work constitutes direct\n",
      "      or contributory patent infringement, then any patent licenses\n",
      "      granted to You under this License for that Work shall terminate\n",
      "      as of the date such litigation is filed.\n",
      "\n",
      "   4. Redistribution. You may reproduce and distribute copies of the\n",
      "      Work or Derivative Works thereof in any medium, with or without\n",
      "      modifications, and in Source or Object form, provided that You\n",
      "      meet the following conditions:\n",
      "\n",
      "      (a) You must give any other recipients of the Work or\n",
      "          Derivative Works a copy of this License; and\n",
      "\n",
      "      (b) You must cause any modified files to carry prominent notices\n",
      "          stating that You changed the files; and\n",
      "\n",
      "      (c) You must retain, in the Source form of any Derivative Works\n",
      "          that You distribute, all copyright, patent, trademark, and\n",
      "          attribution notices from the Source form of the Work,\n",
      "          excluding those notices that do not pertain to any part of\n",
      "          the Derivative Works; and\n",
      "\n",
      "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
      "          distribution, then any Derivative Works that You distribute must\n",
      "          include a readable copy of the attribution notices contained\n",
      "          within such NOTICE file, excluding those notices that do not\n",
      "          pertain to any part of the Derivative Works, in at least one\n",
      "          of the following places: within a NOTICE text file distributed\n",
      "          as part of the Derivative Works; within the Source form or\n",
      "          documentation, if provided along with the Derivative Works; or,\n",
      "          within a display generated by the Derivative Works, if and\n",
      "          wherever such third-party notices normally appear. The contents\n",
      "          of the NOTICE file are for informational purposes only and\n",
      "          do not modify the License. You may add Your own attribution\n",
      "          notices within Derivative Works that You distribute, alongside\n",
      "          or as an addendum to the NOTICE text from the Work, provided\n",
      "          that such additional attribution notices cannot be construed\n",
      "          as modifying the License.\n",
      "\n",
      "      You may add Your own copyright statement to Your modifications and\n",
      "      may provide additional or different license terms and conditions\n",
      "      for use, reproduction, or distribution of Your modifications, or\n",
      "      for any such Derivative Works as a whole, provided Your use,\n",
      "      reproduction, and distribution of the Work otherwise complies with\n",
      "      the conditions stated in this License.\n",
      "\n",
      "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
      "      any Contribution intentionally submitted for inclusion in the Work\n",
      "      by You to the Licensor shall be under the terms and conditions of\n",
      "      this License, without any additional terms or conditions.\n",
      "      Notwithstanding the above, nothing herein shall supersede or modify\n",
      "      the terms of any separate license agreement you may have executed\n",
      "      with Licensor regarding such Contributions.\n",
      "\n",
      "   6. Trademarks. This License does not grant permission to use the trade\n",
      "      names, trademarks, service marks, or product names of the Licensor,\n",
      "      except as required for reasonable and customary use in describing the\n",
      "      origin of the Work and reproducing the content of the NOTICE file.\n",
      "\n",
      "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
      "      agreed to in writing, Licensor provides the Work (and each\n",
      "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
      "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
      "      implied, including, without limitation, any warranties or conditions\n",
      "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
      "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
      "      appropriateness of using or redistributing the Work and assume any\n",
      "      risks associated with Your exercise of permissions under this License.\n",
      "\n",
      "   8. Limitation of Liability. In no event and under no legal theory,\n",
      "      whether in tort (including negligence), contract, or otherwise,\n",
      "      unless required by applicable law (such as deliberate and grossly\n",
      "      negligent acts) or agreed to in writing, shall any Contributor be\n",
      "      liable to You for damages, including any direct, indirect, special,\n",
      "      incidental, or consequential damages of any character arising as a\n",
      "      result of this License or out of the use or inability to use the\n",
      "      Work (including but not limited to damages for loss of goodwill,\n",
      "      work stoppage, computer failure or malfunction, or any and all\n",
      "      other commercial damages or losses), even if such Contributor\n",
      "      has been advised of the possibility of such damages.\n",
      "\n",
      "   9. Accepting Warranty or Additional Liability. While redistributing\n",
      "      the Work or Derivative Works thereof, You may choose to offer,\n",
      "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
      "      or other liability obligations and/or rights consistent with this\n",
      "      License. However, in accepting such obligations, You may act only\n",
      "      on Your own behalf and on Your sole responsibility, not on behalf\n",
      "      of any other Contributor, and only if You agree to indemnify,\n",
      "      defend, and hold each Contributor harmless for any liability\n",
      "      incurred by, or claims asserted against, such Contributor by reason\n",
      "      of your accepting any such warranty or additional liability.\n",
      "\n",
      "   END OF TERMS AND CONDITIONS\n",
      "   APPENDIX: How to apply the Apache License to your work.\n",
      "\n",
      "      To apply the Apache License to your work, attach the following\n",
      "      boilerplate notice, with the fields enclosed by brackets \"[]\"\n",
      "      replaced with your own identifying information. (Don't include\n",
      "      the brackets!)  The text should be enclosed in the appropriate\n",
      "      comment syntax for the file format. We also recommend that a\n",
      "      file or class name and description of purpose be included on the\n",
      "      same \"printed page\" as the copyright notice for easier\n",
      "      identification within third-party archives.\n",
      "\n",
      "   Copyright [yyyy] [name of copyright owner]\n",
      "\n",
      "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "   you may not use this file except in compliance with the License.\n",
      "   You may obtain a copy of the License at\n",
      "\n",
      "       http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "   Unless required by applicable law or agreed to in writing, software\n",
      "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "   See the License for the specific language governing permissions and\n",
      "   limitations under the License.\n",
      "\n",
      "Location: /home/user/anaconda3/lib/python3.13/site-packages\n",
      "Requires: alembic, docker, Flask, graphene, gunicorn, Jinja2, markdown, matplotlib, mlflow-skinny, numpy, pandas, pyarrow, scikit-learn, scipy, sqlalchemy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de869b3c-d405-4648-aec1-13cc4ee022dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/myenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "592990bb-dba2-4012-8f29-6daa1d0b7666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
      "  Using cached mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
      "  Using cached mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow)\n",
      "  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (46.0.3)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow)\n",
      "  Using cached huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: matplotlib<4 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (3.10.6)\n",
      "Requirement already satisfied: numpy<3 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (21.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (1.7.2)\n",
      "Requirement already satisfied: scipy<2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow) (1.16.2)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Using cached sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.1)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached fastapi-0.121.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.45)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.12.4)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.5)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (4.15.0)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.7)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2025.10.5)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in ./anaconda3/envs/myenv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
      "Using cached mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
      "Using cached mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
      "Using cached mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Using cached databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.121.3-py3-none-any.whl (109 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Using cached google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Using cached huey-2.5.4-py3-none-any.whl (76 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m766.1 kB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m529.0 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: huey, zipp, uvicorn, sqlparse, pyasn1, protobuf, Mako, itsdangerous, gunicorn, greenlet, graphql-relay, blinker, annotated-doc, starlette, sqlalchemy, rsa, pyasn1-modules, opentelemetry-proto, importlib_metadata, graphene, Flask, docker, opentelemetry-api, google-auth, Flask-CORS, fastapi, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: protobuf‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/33\u001b[0m [pyasn1]e]\n",
      "\u001b[2K    Found existing installation: protobuf 5.29.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/33\u001b[0m [pyasn1]\n",
      "\u001b[2K    Uninstalling protobuf-5.29.3:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/33\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled protobuf-5.29.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/33\u001b[0m [pyasn1]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m33/33\u001b[0m [mlflow]32/33\u001b[0m [mlflow]skinny]]dk]onventions]\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Mako-1.3.10 alembic-1.17.2 annotated-doc-0.0.4 blinker-1.9.0 databricks-sdk-0.73.0 docker-7.1.0 fastapi-0.121.3 google-auth-2.43.0 graphene-3.4.3 graphql-relay-3.2.0 greenlet-3.2.4 gunicorn-23.0.0 huey-2.5.4 importlib_metadata-8.7.0 itsdangerous-2.2.0 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-api-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 protobuf-6.33.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 sqlalchemy-2.0.44 sqlparse-0.5.3 starlette-0.50.0 uvicorn-0.38.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!/home/user/anaconda3/envs/myenv/bin/python -m pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668c86a-8262-417e-a4f9-aaa504857f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
